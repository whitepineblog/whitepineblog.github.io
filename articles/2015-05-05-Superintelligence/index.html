<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
    <meta name="viewport" content="width=device-width">
    <title>Superintelligece By Nick Bostrom - Some Notes
    </title>
    <link rel="alternate" href="http://localhost:8080/feed.xml" type="application/rss+xml" title="">
    <link rel="stylesheet" href="http://fonts.googleapis.com/css?family=Lora:400,700,400italic,700italic|Anonymous+Pro:400,700,400italic,700italic|Merriweather:400,700,300">
    <link rel="stylesheet" href="/css/main.css">
  </head>
  <body class="article-detail">
    <header class="header">
      <div class="content-wrap">
        <h1>Superintelligece By Nick Bostrom</h1>
      </div>
    </header>
    <div id="content">
      <div class="content-wrap">
        <article class="article">
          <section class="content"><p>What happens when humanity create something more powerful then&nbsp;itself?</p>
<p><span class="more"></span></p>
<p>Can we replicate human level intelligence in a machine?  Not yet. But many feel that it won’t be very long until we do.  Very long being sometime in the next 100&nbsp;years.</p>
<p>We have narrow <span class="caps">AI</span> with speech recognition, pattern recognition, chess playing algorithms, Watson and other technologies we use all th&nbsp;time.</p>
<p>Where will the enhanced <span class="caps">AI</span> revolution come from? It could come from a large corporation or nation level project, or maybe a lone person discovers or creates an algorithm that wasn’t thought of before. But when it happens what’s in store for the rest of us on the&nbsp;planet?</p>
<p>What will be the motivations of the <span class="caps">AI</span>? Will it have morals? What will be the results of having an intelligence that is as far beyond humans as humans are beyond a worm or an&nbsp;ant?</p>
<p>Building in safety, controls and coming up with good solutions to the motivation problem is going to require solving some interesting&nbsp;problems.</p>
<p>If you had an <span class="caps">AI</span> where it’s primary motive was to create the most paperclips as effectively as it could there is a possibility it could eventually replace the surface of the earth, the solar system and the reachable universe with paperclip making factories.  Not really a desirable outcome. So how do you give an AI a respect for life, and the desires of the humans that created it? Precise definitions can be hard as well. Say assigning an AI’s primary task to bring happiness to humanity could result in the AI implanting electrodes in everyones brains to make them feel happy, or to maximize the amount of happiness of the universe it could destroy biological life and run simulations that create happiness in simulated&nbsp;humans.</p>
</section>
        </article>
      </div>
    </div>
    <footer>
      <div class="content-wrap">
        <div class="nav"><a href="/">« Full blog</a></div>
        <section class="about"><p>A blog by <a href="http://whitepinedev.com">Christen</a> </p>

        </section>
        <section class="copy">
          <p>&copy; 2016 Christen Thompson &mdash; powered by&nbsp;<a href="https://github.com/jnordberg/wintersmith">Wintersmith</a>
          </p>
        </section>
      </div>
    </footer>
  </body>
</html>