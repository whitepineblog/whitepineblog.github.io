---
layout: post
title:  "Superintelligece By Nick Bostrom"
date:   2015-5-05
categories: notes books
---

What happens when humanity create something more powerful then itself?

Can we replicate human level intelligence in a machine?  Not yet. But many feel that it won't be very long until we do.  Very long being sometime in the next 100 years.

We have narrow AI with speech recognition, pattern recognition, chess playing algorithms, Watson and other technologies we use all th time.

Where will the enhanced AI revolution come from? It could come from a large corporation or nation level project, or maybe a lone person discovers or creates an algorithm that wasn't thought of before. But when it happens what's in store for the rest of us on the planet?

What will be the motivations of the AI? Will it have morals? What will be the results of having an intelligence that is as far beyond humans as humans are beyond a worm or an ant?

Building in safety, controls and coming up with good solutions to the motivation problem is going to require solving some interesting problems.

If you had an AI where it's primary motive was to create the most paperclips as effectively as it could there is a possibility it could eventually replace the surface of the earth, the solar system and the reachable universe with paperclip making factories.  Not really a desirable outcome. So how do you give an AI a respect for life, and the desires of the humans that created it? Precise definitions can be hard as well. Say assigning an AI's primary task to bring happiness to humanity could result in the AI implanting electrodes in everyones brains to make them feel happy, or to maximize the amount of happiness of the universe it could destroy biological life and run simulations that create happiness in simulated humans.


